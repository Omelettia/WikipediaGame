{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "615babfa",
   "metadata": {},
   "source": [
    "#1.Code Python để tạo đồ thị có hướng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe515af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mwxml in c:\\users\\asiat\\anaconda3\\lib\\site-packages (0.3.3)\n",
      "Requirement already satisfied: jsonschema>=2.5.1 in c:\\users\\asiat\\anaconda3\\lib\\site-packages (from mwxml) (4.19.2)\n",
      "Requirement already satisfied: mwcli>=0.0.2 in c:\\users\\asiat\\anaconda3\\lib\\site-packages (from mwxml) (0.0.3)\n",
      "Requirement already satisfied: mwtypes>=0.3.0 in c:\\users\\asiat\\anaconda3\\lib\\site-packages (from mwxml) (0.3.2)\n",
      "Requirement already satisfied: para>=0.0.1 in c:\\users\\asiat\\anaconda3\\lib\\site-packages (from mwxml) (0.0.8)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\asiat\\anaconda3\\lib\\site-packages (from jsonschema>=2.5.1->mwxml) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\asiat\\anaconda3\\lib\\site-packages (from jsonschema>=2.5.1->mwxml) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\asiat\\anaconda3\\lib\\site-packages (from jsonschema>=2.5.1->mwxml) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\asiat\\anaconda3\\lib\\site-packages (from jsonschema>=2.5.1->mwxml) (0.10.6)\n",
      "Requirement already satisfied: docopt in c:\\users\\asiat\\anaconda3\\lib\\site-packages (from mwcli>=0.0.2->mwxml) (0.6.2)\n",
      "Requirement already satisfied: jsonable>=0.3.0 in c:\\users\\asiat\\anaconda3\\lib\\site-packages (from mwtypes>=0.3.0->mwxml) (0.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install mwxml\n",
    "import bz2\n",
    "import pickle\n",
    "import re\n",
    "import mwxml\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a836b82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đường dẫn đến file xml\n",
    "dump_path = r\"simplewiki-20240220-pages-articles-multistream.xml.bz2\"\n",
    "\n",
    "# Các files ouput\n",
    "graph_file = \"graph_with_attributes.pkl\"\n",
    "features_file = \"article_features.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e3c69a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directed_graph_and_extract_features(dump_path):\n",
    "    # Tạo đồ thị có hướng với networkx\n",
    "    graph = nx.DiGraph()\n",
    "\n",
    "    # Lưu các articles(các bài viết của wiki)\n",
    "    article_titles = set()\n",
    "\n",
    "    # List đế lưu các đặc trưng(features) của các article\n",
    "    features = []\n",
    "\n",
    "    # NLTK stopwords\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "    # Mở file xml bằng thư viện bz2\n",
    "    with bz2.open(dump_path, \"rt\", encoding=\"utf-8\") as dump_file:\n",
    "        dump = mwxml.Dump.from_file(dump_file)\n",
    "\n",
    "        # Đếm tổng số articles\n",
    "        total_count = 0\n",
    "        for page in dump:\n",
    "            total_count += 1\n",
    "            if page.namespace == 0 and not page.redirect:\n",
    "        #Cho tên các articles vào set article_titles để kiểm tra\n",
    "                title = page.title\n",
    "                article_titles.add(title)\n",
    "                       \n",
    "        # Reset để có thể lướt qua các articles lại từ đầu\n",
    "        dump_file.seek(0)\n",
    "        dump = mwxml.Dump.from_file(dump_file)\n",
    "\n",
    "        # Lần lượt đi qua các trang để lấy tên articles và đặc trưng \n",
    "        # Sử dụng tdqm tạo process bar để kiểm tra tiến độ\n",
    "        for page in tqdm(dump, total=total_count, unit=\"articles\", desc=\"Processing articles\"):\n",
    "            if page.namespace == 0 and not page.redirect:\n",
    "                # Lấy tên các articles\n",
    "                title = page.title\n",
    "\n",
    "                # Đi qua các revision\n",
    "                for revision in page:\n",
    "                    if revision.text:\n",
    "                        # Lấy text từ revision\n",
    "                        tokens = word_tokenize(revision.text)\n",
    "\n",
    "                        # Tạo bag-of_words\n",
    "                        bag_of_words = \" \".join(tokens)\n",
    "\n",
    "                        # Lấy các đường links trong revision\n",
    "                        hyperlinks = re.findall(r\"\\[\\[(.*?)]]\", revision.text)\n",
    "                        hyperlinks_cleaned = [hyperlink.split(\"|\")[0] for hyperlink in hyperlinks]\n",
    "\n",
    "                        # Đếm số từ và link có trong articles\n",
    "                        word_count = len(tokens)\n",
    "                        link_count = len(hyperlinks_cleaned)\n",
    "\n",
    "                        # Thêm node vào graph và các attributes cần để chạy heuristic function cho A*\n",
    "                        attributes = {\n",
    "                            \"Word Count\": word_count,\n",
    "                            \"Link Count\": link_count,\n",
    "                            \"Bag of Words\": bag_of_words\n",
    "                        }\n",
    "                    # Kiểm tra xem article có trong graph chưa để cho vào\n",
    "                    if title in graph.nodes:\n",
    "                        node_attributes = graph.nodes[title]\n",
    "                        node_attributes.update(attributes)\n",
    "                    else:\n",
    "                    #Nếu có thì cập nhật attributes\n",
    "                        graph.add_node(title, **attributes)\n",
    "\n",
    "                    features.append((title, word_count, link_count, bag_of_words))\n",
    "                    for hyperlink in hyperlinks_cleaned:\n",
    "                        #Kiếm tra xem link có dẫn đến 1 article không\n",
    "                        if hyperlink in article_titles:\n",
    "                            if hyperlink not in graph.nodes:\n",
    "                                # Nếu article chưa có thì tạo làm node\n",
    "                                graph.add_node(hyperlink)\n",
    "                            # Thêm cạnh vào graph    \n",
    "                            graph.add_edge(title, hyperlink)\n",
    "\n",
    "    # Lưa graph lại dưới file pickle\n",
    "    with open(graph_file, \"wb\") as file:\n",
    "        pickle.dump(graph, file)\n",
    "\n",
    "    # Tạo DataFrame với các đặc trưng\n",
    "    df = pd.DataFrame(features, columns=[\"Title\", \"Word Count\", \"Link Count\", \"Bag of Words\"])\n",
    "\n",
    "    # Lưu DataFrame với các đặc trưng vao CSV file\n",
    "    df.to_csv(features_file, index=False)\n",
    "\n",
    "    return graph, df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c956e48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6054b19b40c04a0993fec8dfb06522dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing articles:   0%|          | 0/472626 [00:00<?, ?articles/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gọi hàm\n",
    "graph, df = create_directed_graph_and_extract_features(dump_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a0a906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thông báo khi hoàn thành\n",
    "print('Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64d173b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
